{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJR6GxEKTHHf"
   },
   "source": [
    "## Business Understanding\n",
    "The real estate market requires accurate pricing predictions to help sellers set competitive prices\n",
    "and buyers make informed decisions. This dataset contains detailed features of residential homes\n",
    "in Ames, Iowa, including physical characteristics, location details, and sale prices.\n",
    "The goal of this project is to analyze various factors influencing house prices in these locations and develop predictive models to estimate house prices based on these factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzw66DdcUJsL"
   },
   "source": [
    "## Problem Statement\n",
    "To develop a predictive model to accurately estimate house sale prices based on various property\n",
    "features, enabling stakeholders to make data-driven pricing decisions and identify key factors\n",
    "influencing property values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bohRw6pIUDEI"
   },
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THp-IJUYGumW"
   },
   "source": [
    "1. Build an accurate predictive model for house prices.\n",
    "2. Identify key features influencing house prices.\n",
    "3. Provide actionable insights for real estate stakeholders.\n",
    "4. Compare different machine learning models for optimal performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABa5BAdmUWXu"
   },
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSRJLRW_FF1R",
    "outputId": "c1070723-7d6e-40e9-98c0-19a871cbfec7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading the ames dataset\n",
    "df = pd.read_csv('ames.csv')\n",
    "\n",
    "# Basic data understanding\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst few rows:\\n\", df.head())\n",
    "print(\"\\nData Info:\\n\")\n",
    "df.info()\n",
    "print(\"\\nBasic Statistics:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRJ6bvOZpgrA"
   },
   "source": [
    "**Dataset Overview:**\n",
    "\n",
    "**Size and Structure**:The dataset contains 1460 rows and 81 columns.\n",
    "The dataset includes a mix of numerical (int64, float64) and categorical (object) data types.\n",
    "\n",
    "**Target Variable**:The primary target variable is \"SalePrice,\" which indicates the price of the house.\n",
    "\n",
    "**Missing Values**:A significant number of columns have missing values. Notably:\"Alley,\" \"PoolQC,\" \"Fence,\" and \"MiscFeature\" have a very high percentage.\n",
    "This indicates that data cleaning and imputation will be crucial steps.\n",
    "\n",
    "**Data Types**:The dataset has 35 integer columns, 3 float columns, and 43 object (categorical) columns. This highlights the need for appropriate handling of both numerical and categorical features.\n",
    "\n",
    "\n",
    "**Key Statistical Insights:**\n",
    "\n",
    "***SalePrice Distribution:***\n",
    "- The average sale price is approximately $180,921.\n",
    "\n",
    "- The minimum sale price is $34,900.\n",
    "\n",
    "- The maximum is $755,000, indicating a wide range of property values.\n",
    "- The standard deviation of sale price is quite high, meaning that the sale prices are spread out.\n",
    "\n",
    "***Overall Quality and Condition:***\n",
    "\n",
    "- The \"OverallQual\" (overall quality) and \"OverallCond\" (overall condition) columns have a range from 1 to 10 and 1 to 9, respectively, providing a numerical assessment of property quality.\n",
    "- The mean of OverallQual is 6.09, and the mean of OverallCond is 5.57.\n",
    "\n",
    "***Year Built and Remodeled:***\n",
    "The \"YearBuilt\" and \"YearRemodAdd\" columns show a range of construction and remodeling years, providing a timeline for property development.\n",
    "\n",
    "***Lot Area and Lot Frontage:***\n",
    "\"LotArea\" and \"LotFrontage\" provide information about the size and dimensions of the property. The large standard deviation of lot area shows that there is a large variety of lot sizes.\n",
    "\n",
    "***Basement and Garage Features:***\n",
    "Columns related to basement and garage features (e.g., \"BsmtFinSF1,\" \"GarageCars,\" \"GarageArea\") provide insights into the property's infrastructure.\n",
    "\n",
    "***Porch and Deck Areas:***\n",
    "\"WoodDeckSF,\" \"OpenPorchSF,\" and other porch-related columns indicate the presence and size of outdoor living spaces.\n",
    "\n",
    "***Pool and Miscellaneous Features:***\n",
    "The \"PoolArea\" and \"MiscVal\" columns indicate that pools and other miscellaneous features are relatively rare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGzNv5-fUh84"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2kTIGP_UrGh"
   },
   "source": [
    "### Correct Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jAdW5t6KtAy"
   },
   "outputs": [],
   "source": [
    "# Converting the numerical columns into the right format\n",
    "\n",
    "numeric_cols = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2','BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea','GarageArea', 'SalePrice']\n",
    "df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQzZyG5tU4LO"
   },
   "source": [
    "### Handling NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQQ7eHRPLWf1"
   },
   "outputs": [],
   "source": [
    "# Replacing the 'NA' strings with np.nan\n",
    "df.replace('NA', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ulo_Z2cQVB0n"
   },
   "source": [
    "### Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvNX6bLWQ4dM"
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ID5drq2HVFRk"
   },
   "source": [
    "### Other cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EvvovPW1TWfE",
    "outputId": "72cd6064-c59c-495f-b150-08c8044e6543"
   },
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(\"\\nMissing Values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efjPxBgDTl5M"
   },
   "outputs": [],
   "source": [
    "# Filling the missing values\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].median())\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(0)\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(df['YearBuilt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zE3PQXPOrhhy"
   },
   "outputs": [],
   "source": [
    "# Droping columns with too many missing values (if over 50% are missing)\n",
    "threshold = len(df) * 0.5\n",
    "df = df.dropna(thresh=threshold, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2I5pRR7VORE"
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VyYYKp9bJbW"
   },
   "outputs": [],
   "source": [
    "df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
    "df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n",
    "df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v0T89EScVZe3"
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TmXBlpVkVbmK"
   },
   "source": [
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "COdSCexorzjk",
    "outputId": "18edb1fd-a229-481d-a396-1aa59db2dd03"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['SalePrice'], kde=True)\n",
    "plt.title('Distribution of Sale Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-KYxLqWsQhS"
   },
   "source": [
    "The histogram provides a visual representation of the distribution of sale prices, highlighting its right-skewed nature, the central tendency, spread, and potential outliers.\n",
    "The distribution of sale prices is right-skewed. This means that the tail of the distribution extends further to the right (higher prices), indicating that there are more houses with lower sale prices and fewer houses with very high sale prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptIiepiWVivy"
   },
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 584
    },
    "id": "E0Lymz_WsiTk",
    "outputId": "3dc0b5b9-6535-49e1-9d76-d8a866d5df4f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='GrLivArea', y='SalePrice', data=df)\n",
    "plt.title('Relationship of Sale Price vs Living Area')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYYUncZiuPUg"
   },
   "source": [
    "The scatter plot reveals a positive correlation between living area and sale price. This means that, in general, houses with larger living areas tend to have higher sale prices.\n",
    "\n",
    "The correlation appears to be moderately strong, but not perfect. While there's a clear trend, there's also some scatter, indicating that other factors besides living area also influence sale price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UknBIlZ_Vwgx"
   },
   "source": [
    "### Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 811
    },
    "id": "NbFUyvxIughj",
    "outputId": "aa58f6c6-1ca7-4505-9973-e56decc4adf6"
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "correlation = numeric_df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation, annot=False, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZdCceIpz9ME"
   },
   "source": [
    "The correlation matrix heatmap above provides a visual overview of the relationships between numerical features in the dataset.\n",
    "\n",
    "Some of the Key Observations are as below;\n",
    "\n",
    "**Strong Positive Correlations:** You can identify strong positive correlations (dark red areas)\n",
    "- \"OverallQual\" and \"SalePrice\" (as expected, higher quality houses sell for more).\n",
    "- \"GarageCars\" and \"GarageArea\" (more garage space correlates with more cars).\n",
    "- \"GrLivArea\" and \"SalePrice\" (larger living area correlates with higher price).\n",
    "- \"TotalBsmtSF\" and \"1stFlrSF\" (a larger total basement square footage correlates with a larger 1st floor square footage).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng-5i5lzWAEd"
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yrpXRjGWDDr"
   },
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCD2Zf1abJ34"
   },
   "outputs": [],
   "source": [
    "# Encoding categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('SalePrice', axis=1)\n",
    "y = df['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h6gr2PVVWHIH"
   },
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-2GsRTHbcZs",
    "outputId": "0de5aff1-4cb7-4c57-b6a5-d52f7c35dc66"
   },
   "outputs": [],
   "source": [
    "#Performing Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5CvirjOchh_"
   },
   "source": [
    "This implies that 20% of our data is in test and 80% trains the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F1r43YPFcuTY"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing data (using the same scaler fitted on training data)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4JBehirdyfm"
   },
   "source": [
    "Scaling, standardizes feature values so that some values are not penalized unfairly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fMFm7jvWJTl"
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNJl_i0zWN8s"
   },
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "r17FVN0Dha7b",
    "outputId": "6933d9b0-4951-4432-b83b-40469d0da3bc"
   },
   "outputs": [],
   "source": [
    "# fitting a ridge regression model\n",
    "\n",
    "# Import a ridge model from sckit-learn\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Initialize and train the Ridge Regression model\n",
    "ridge_model = Ridge(alpha=100, solver = \"sag\", random_state=1)\n",
    "ridge_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycklmjEpWRVr"
   },
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVEfOx6aWYZa"
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "8zYm6ZRGmLYU",
    "outputId": "b2e3d3de-b58a-4c44-b8a9-230e720cfe30"
   },
   "outputs": [],
   "source": [
    "# logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "logreg_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TDISGY-Wek6"
   },
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "9YYaP79PoM9a",
    "outputId": "7fa9ffd5-13e4-4d81-e6ae-c762fa98dfff"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize and train the decision tree model\n",
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "tree_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yRtETSEMWi8C"
   },
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "XrJYrY2Mo-wF",
    "outputId": "654ab92c-d324-4c62-f697-4c37166b7e3f"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize and train the random forest model\n",
    "rf_model = RandomForestRegressor(random_state=42, n_estimators=100) # You can adjust hyperparameters\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHfhuih5Xswu"
   },
   "source": [
    "#### K-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "2NcJEYPfpPar",
    "outputId": "b5f9163e-4aa9-484e-f0bd-c65e57dc6fae"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Initialize and train the K-NN model\n",
    "knn_model = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "knn_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xO5zgK4Xv-e"
   },
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "XAvWDPGipb57",
    "outputId": "677fa19d-d915-4dac-fccc-b400f9d7910b"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_model = SVR(kernel='linear') # You can change the kernel (e.g., 'rbf', 'poly')\n",
    "svm_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6CFHjx2XyvZ"
   },
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "N7u7LBsBpnWu",
    "outputId": "1869fe20-7b5d-4fdf-b192-2f88c67f5dd8"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initialize and train the Gaussian Naive Bayes model\n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4-qTBR_t3syN",
    "outputId": "6e63cb72-400e-4cd0-cd61-00b007cf2a97"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'K-NN': KNeighborsRegressor(),\n",
    "    'SVM': SVR()\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}: RMSE = {metrics['RMSE']:.2f}, R2 = {metrics['R2']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSzAPoAe8_11"
   },
   "source": [
    "From the above trained models below are the observations;\n",
    "\n",
    "- Linear Regression (RMSE: 36,658.46, R²: 0.81)\n",
    "\n",
    "Performs well, explaining 81% of variance.Moderate RMSE, meaning prediction errors are relatively low.\n",
    "\n",
    "- Decision Tree (RMSE: 38,703.79, R²: 0.79)\n",
    "\n",
    "Slightly worse than Linear Regression.\n",
    "More prone to overfitting, causing minor performance drop.\n",
    "\n",
    "- Random Forest (RMSE: 28,328.87, R²: 0.89)\n",
    "\n",
    "Lowest RMSE and highest R², meaning it provides the **most accurate predictions.**\n",
    "Likely benefits from ensemble averaging, reducing overfitting.\n",
    "\n",
    "- K-NN (RMSE: 40,809.63, R²: 0.77)\n",
    "\n",
    "Weaker performance, higher error.\n",
    "May struggle with high-dimensional data or inappropriate K-value.\n",
    "\n",
    "- SVM (RMSE: 86,886.76, R²: -0.04)\n",
    "\n",
    "Negative R² means it performs worse than a simple mean predictor.\n",
    "Very high RMSE suggests it fails to capture the underlying pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3euf0SHX5a6"
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqptD3BHrHed",
    "outputId": "ddabdafe-ee01-4691-d870-ddfe3c2bbdfc"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_b_wJjhX9rj"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvAItBC462EW",
    "outputId": "4479a18e-80d1-4e09-be00-5bb4ad1efc0d"
   },
   "outputs": [],
   "source": [
    "# Evaluate the best model\n",
    "y_pred_best = best_rf.predict(X_test_scaled)\n",
    "rmse_best = np.sqrt(mean_squared_error(y_test, y_pred_best))\n",
    "r2_best = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"Best Random Forest - RMSE: {rmse_best:.2f}, R2: {r2_best:.2f}\")\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': best_rf.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "print(\"\\nTop 10 Important Features:\\n\", feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iAO47pIODbYn"
   },
   "source": [
    "With an RMSE of 28165.18 and R-Squared of 0.89, Random Forest model is definitely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M1VL3VMvYCjO"
   },
   "source": [
    "### Conclusion and Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ylslzd-FJ9l"
   },
   "source": [
    "From my objectives stated above;\n",
    "\n",
    "**Below is my Conclusion:**\n",
    "The Random Forest model with tuned hyperparameters provided the best performance for predicting house prices.\n",
    "Key features influencing prices include TotalSF, GrLivArea, and OverallQual.\n",
    "\n",
    "**Below are my Recommendations:**\n",
    "1. Focus on property size and quality for pricing decisions.\n",
    "2. Use the model for initial price estimates.\n",
    "3. Future improvements could include using advanced ensemble methods and feature selection techniques.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "ng-5i5lzWAEd",
    "h6gr2PVVWHIH",
    "GNJl_i0zWN8s"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
